This project demonstrates the complete pipeline for fine-tuning a TinyLlama model using LoRA on a curated dataset of 150+ CLI-related Q&A pairs, and wrapping it into a CLI agent interface for real-world command-line assistance.

âœ… Project Structure

â”œâ”€â”€ agent.py # CLI agent using fine-tuned LoRA adapter
â”œâ”€â”€ base_agent.py # Baseline agent using original TinyLlama
â”œâ”€â”€ cli_qa_dataset.json # Curated dataset of 150+ command-line Q&A pairs
â”œâ”€â”€ logs/ # Logs of agent interactions
â”‚ â””â”€â”€ trace.jsonl
â”œâ”€â”€ lora_adapter/ # Output directory for saved LoRA adapter weights
â”œâ”€â”€ tinyllama_lora_cpu_output/ # Training outputs
â”œâ”€â”€ eval_static.md # Static evaluation report (Base vs Finetuned)
â”œâ”€â”€ eval_dynamic.md # Real-time evaluation from agent runs
â”œâ”€â”€ report.md # One-page summary of data, training, results
â”œâ”€â”€ eval_metrics.py # Computes ROUGE-L scores for static evaluation
â””â”€â”€ README.md # (You are here)

âš™ï¸ Setup Instructions

1. ğŸ” Clone Repo & Create Environment

git clone <your-private-repo-link>
cd <project-folder>
python -m venv venv
source venv/bin/activate # On Windows: venv\Scripts\activate

2. ğŸ“¦ Install Requirements

pip install -r requirements.txt

If `requirements.txt` is missing, install manually:

pip install torch transformers datasets peft rouge-score accelerate

ğŸ§  Run CLI Agent

â–¶ï¸ Fine-Tuned Model (agent.py)

python agent.py "Create a new Git branch and switch to it"

â–¶ï¸ Base Model (base_agent.py)

python base_agent.py "Create a new Git branch and switch to it"

Logs will be saved automatically to `logs/trace.jsonl`

ğŸ“š Train the Model (LoRA + CPU)

Run your training script (e.g., `train.py` or `model.py`):

python model.py

This will:

- Load `cli_qa_dataset.json`
- Fine-tune `TinyLlama/TinyLlama-1.1B-Chat-v1.0`
- Save the adapter to `lora_adapter/`

ğŸ“Š Evaluate

1. Static Evaluation (Base vs Fine-Tuned)
   Edit and review `eval_static.md`

2. Dynamic Evaluation (CLI Agent)
   Run 7 test queries â†’ `logs/trace.jsonl` â†’ summarize in `eval_dynamic.md`

3. ROUGE-L Metric
   python eval_metrics.py

ğŸ“ Submission Checklist
âœ… Source & build instructions (`README.md`) â€” end-to-end reproducible
âœ… data/ â€” JSON file(s) containing â‰¥ 150 validated Q&A pairs (`cli_qa_dataset.json`)
âœ… Training script + LoRA adapter files (`model.py`, `lora_adapter/` â‰¤ 500 MB)
âœ… agent.py â€” Runnable as: `python agent.py "Create a new Git branch and switch to it"`
âœ… eval_static.md â€” Base vs. fine-tuned answers + metrics
âœ… eval_dynamic.md â€” Agent runs + 0-2 scoring table
âœ… report.md â€” One-page summary
âœ… Demo video â€” â‰¤ 5 min, Loom/MP4 format
